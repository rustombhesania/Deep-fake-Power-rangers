# Audio Deepfake Detection using ASVspoof2019

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-Latest-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## 🎯 Project Overview

This project focuses on **Audio Deepfake Detection** using machine learning techniques to identify synthetic voices generated by AI tools like Text-to-Speech (TTS) or voice conversion systems. The project combines speech processing, machine learning, and forensics to detect fake audio with high accuracy.

## 🎵 What is Audio Deepfake Detection?

Audio deepfakes are synthetic speech generated using AI that can mimic real human voices. This technology poses significant security risks for:
- Identity verification systems
- Voice-based authentication
- Media authenticity verification
- Legal and forensic applications

Our system acts as a **Countermeasure (CM)** to detect spoofed audio before it reaches **Automatic Speaker Verification (ASV)** systems.

## 📊 Dataset: ASVspoof2019

We utilize the ASVspoof2019 dataset, specifically the **Logical Access (LA)** subset:

### Dataset Subsets
| Subset | Full Name | Purpose | Our Focus |
|--------|-----------|---------|-----------|
| **LA** | Logical Access | Detects TTS and VC-based attacks | ✅ **Primary Focus** |
| **PA** | Physical Access | Detects replay attacks in physical environments | ❌ Not included |

### Why LA (Logical Access)?
- **TTS Detection**: Identifies text-to-speech generated audio
- **Voice Conversion**: Detects voice conversion attacks
- **Digital Spoofing**: Focuses on digitally synthesized attacks
- **Real-world Relevance**: Most applicable to modern deepfake scenarios

## 🔧 Technical Approach

### Dual Pipeline Architecture

We implement two complementary feature extraction pipelines:

1. **CPU Pipeline (Librosa)** 🖥️
   - Fast prototyping and development
   - Lightweight for inference
   - Easy debugging and visualization

2. **GPU Pipeline (Torchaudio)** 🚀
   - Scalable batch processing
   - GPU-accelerated training
   - Production-ready performance

## 🎼 Feature Extraction

Our comprehensive feature extraction includes multiple categories of audio features:

### 🎵 Spectral Features
- **MFCCs** (Mel-Frequency Cepstral Coefficients)
- **STFT** (Short-Time Fourier Transform / Spectrograms)
- **CQT** (Constant-Q Transform)
- **LPC** (Linear Predictive Coefficients)
- **Spectrogram Analysis**

### 📐 Phase-Based Features
- **Group Delay**
- **Phase Spectrum**
- **Relative Phase**

### ⏱️ Temporal Features
- **Zero-Crossing Rate**
- **Energy Contour**
- **Amplitude Envelope**

### 🎙️ Higher-Level Features
- **Formant Analysis**
- **Pitch & Jitter**
- **Voice Source Characteristics**
- **Modulation Spectrum**

## 🏗️ Architecture Overview

```
Audio Input → Feature Extraction → ML Model → Fake/Real Classification
     ↓              ↓                ↓              ↓
  Raw Audio    [Spectral Features]  [CNN/RNN]   [0: Real, 1: Fake]
               [Phase Features]     [RawNet2]
               [Temporal Features]  [AASIST]
               [Higher-level]       [LCNN]
```

## 🔬 Implemented Models

The project includes implementations and benchmarks for state-of-the-art models:

- **CNN-based** classifiers
- **RawNet2** - End-to-end raw audio processing
- **AASIST** - Graph attention networks for spoofing detection
- **LCNN** - Light CNN for efficient processing
- **Self-supervised learning** approaches
- **One-class learning** methods
- **Sequence-based detection** models

## 🚀 Getting Started

### Prerequisites

```bash
pip install librosa torch torchaudio numpy pandas scikit-learn matplotlib
```

### Installation

```bash
git clone https://github.com/rustombhesania/Deep-fake-Power-rangers.git
cd Deep-fake-Power-rangers
pip install -r requirements.txt
```

### Usage

1. **Download ASVspoof2019 Dataset**
   ```bash
   # Download LA subset from official ASVspoof2019 website
   # Place in data/ directory
   ```

2. **Feature Extraction**
   ```python
   # CPU-based extraction with Librosa
   python extract_features_librosa.py --input_dir data/LA --output_dir features/librosa
   
   # GPU-based extraction with Torchaudio
   python extract_features_torchaudio.py --input_dir data/LA --output_dir features/torchaudio
   ```

3. **Model Training**
   ```python
   # Train baseline CNN model
   python train_model.py --model cnn --features librosa
   
   # Train RawNet2 with GPU acceleration
   python train_model.py --model rawnet2 --features torchaudio --device gpu
   ```

4. **Evaluation**
   ```python
   python evaluate.py --model_path models/best_model.pth --test_dir data/LA/eval
   ```

## 📈 Performance Metrics

We evaluate models using standard ASVspoof metrics:

- **Equal Error Rate (EER)** - Primary metric for spoofing detection
- **Accuracy** - Overall classification performance
- **Precision/Recall** - Per-class performance
- **t-DCF** (Tandem Detection Cost Function) - ASVspoof official metric

## 🔬 Research Foundation

This project builds upon cutting-edge research including:

- **ASVspoof2019** Challenge baseline
- **ADD2022** Competition insights
- **RawNet2** - Raw waveform processing
- **AASIST** - Graph attention mechanisms
- **LCNN** - Lightweight architectures
- Self-supervised and one-class learning approaches

## 🎯 Current Development Status

### ✅ Completed
- [x] Dataset analysis and understanding (LA vs PA subsets)
- [x] Feature extraction pipeline design
- [x] Research literature review and model selection
- [x] Dual pipeline architecture (CPU/GPU)

### 🔄 In Progress
- [ ] Implement Librosa-based feature extraction
- [ ] Implement Torchaudio-based feature extraction
- [ ] Train baseline CNN models
- [ ] Benchmark RawNet2 implementation

### 📋 Upcoming
- [ ] Test generalizability with unseen attacks
- [ ] Optimize model performance
- [ ] Deploy production-ready inference pipeline
- [ ] Create web demo interface


## 📚 Key Terms Reference

| Term | Full Form | Description |
|------|-----------|-------------|
| **CM** | Countermeasure | System that detects spoofed/fake audio |
| **ASV** | Automatic Speaker Verification | System that confirms speaker identity |
| **LA** | Logical Access | Digital/software-based spoofing attacks |
| **PA** | Physical Access | Physical replay-based spoofing attacks |
| **TTS** | Text-to-Speech | AI system that converts text to speech |
| **VC** | Voice Conversion | AI system that converts one voice to another |

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- ASVspoof2019 Challenge organizers
- Research community for open-source implementations
- Contributors to Librosa and Torchaudio libraries


---

**🛡️ Ethical Note**: This project is developed for research and defensive purposes to improve audio authentication systems. Please use responsibly and in accordance with applicable laws and ethics guidelines.
